{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet Bayésien\n",
    "Guillaume et Yanis **<3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction du problème \n",
    "\n",
    "Le problème développé dans ce projet est d'implémenter un échantillonneur selon le modèle statistique donné par le pack de données choisi. \n",
    "Nous travaillerons sur le dataset **Eyes**. Il s'agit d'un ensemble de mesures de longueurs d'ondes pour lesquelles les singes qui ont été testés ont une sensibilité maximale. Nos données sont donc en nanomètres.\n",
    "\n",
    "\n",
    "Ce projet s'articulera en trois mouvements :\n",
    "- Importation du dataset\n",
    "- Etude approfondie des modèles statistiques à implémenter\n",
    "- Implémentation d'un sampler de Gibbs pour la génération d'un échantillon suivant les loi données par le dataset **Eyes**. On implémentera un échantillonneur pour chacun des deux modèles présentés dans le dataset, afin de pouvoir se rendre compte de l'effet d'attraction de classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des **Data** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation et analyse des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion du fichier eyes.data.R en Python\n",
    "N = 48\n",
    "y = np.array([\n",
    "    529, 530, 532, 533.1, 533.4, 533.6, 533.7, 534.1, 534.8, 535.3,\n",
    "    535.4, 535.9, 536.1, 536.3, 536.4, 536.6, 537, 537.4, 537.5,\n",
    "    538.3, 538.5, 538.6, 539.4, 539.6, 540.4, 540.8, 542, 542.8,\n",
    "    543, 543.5, 543.8, 543.9, 545.3, 546.2, 548.8, 548.7, 548.9,\n",
    "    549, 549.4, 549.9, 550.6, 551.2, 551.4, 551.5, 551.6, 552.8,\n",
    "    552.9, 553.2\n",
    "])\n",
    "alpha = np.array([1.0, 1.0])\n",
    "\n",
    "# Conversion du fichier eyes.init.R en Python\n",
    "lambda_1 = 535\n",
    "theta = 5\n",
    "sigmasq = 10\n",
    "p1 = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                y\n",
      "count   48.000000\n",
      "mean   541.533333\n",
      "std      7.022406\n",
      "min    529.000000\n",
      "25%    536.050000\n",
      "50%    540.000000\n",
      "75%    548.825000\n",
      "max    553.200000\n"
     ]
    }
   ],
   "source": [
    "# Création d'un DataFrame pour analyser les données\n",
    "df1 = pd.DataFrame({'y': y})\n",
    "print(df1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'analyse de l'équipe de Bowmaker et Al., les chercheurs ont retiré 500nm à toutes les valeurs des observations. Nous allons aussi procéder à ce prétraitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               y\n",
      "count  48.000000\n",
      "mean   41.533333\n",
      "std     7.022406\n",
      "min    29.000000\n",
      "25%    36.050000\n",
      "50%    40.000000\n",
      "75%    48.825000\n",
      "max    53.200000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'y': y-500})\n",
    "print(df.describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on passe y en format numpy pour l'exploitation dans l'échantillonneur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude du modèle statistique non corrigé\n",
    "\n",
    "DAG + lois conditionnelles (normalement c'est juste une gaussienne classique mais il faut prendre en plus le fait qu'on puisse changer de variable pour le lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eyes(n_iter, y, init, hyperparam):\n",
    "    \"\"\"Gibbs sampler for the Eyes dataset : \n",
    "        - n_iter is the length of the chain generated\n",
    "        - y is the known data\n",
    "        - init is the initialisation of the parameters we're estimating\n",
    "        - hyperparam are the initialisations of the parameters of the laws we're estimating\"\"\"\n",
    "    \n",
    "    # On récupère les hyperparamètres de l'entrée\n",
    "\n",
    "    [alpha, beta, mu_theta, sigma_theta, mu_lambda, sigma_lambda] = hyperparam\n",
    "\n",
    "    # On crée les variables de stockage\n",
    "\n",
    "    chaine = np.zeros(n_iter+1, len(init)) # stockage des paramètres\n",
    "    chaine[0] = init\n",
    "    latent = np.zeros(n_iter+1, len(hyperparam)) # stockage des hyperparamètres\n",
    "    n = len(y)\n",
    "    \n",
    "    for k in range(1,n_iter+1):\n",
    "\n",
    "        # Update des T_i\n",
    "        for i in range(n):\n",
    "            expo = -(lambda_1 + theta*(chaine[k-1, i]==2) - (mu_lambda + mu_theta))**2 / (2 * (sigma_lambda**2 + sigma_theta**2 * (chaine[k-1, i]==2)))\n",
    "            p = 1 / np.sqrt(2*np.pi) / (sigma_lambda + sigma_theta) * np.exp(expo)\n",
    "            print(\"p = \", p)\n",
    "            chaine[k,i] = np.random.choice(a=[1,2], p=[1-p,p])\n",
    "\n",
    "        # Update de lambda_1\n",
    "\n",
    "        # Update de theta\n",
    "\n",
    "        # Update de tau^2\n",
    "\n",
    "        # Update de P\n",
    "\n",
    "        # Mise à jour de la chaine \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation de l'échantillonneur de Gibbs pour le modèle initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##def Gibbs_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude du modèle statistique corrigé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skibidi la suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Au boulot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
